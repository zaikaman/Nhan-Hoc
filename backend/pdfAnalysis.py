from flask import request, send_file
import os
import json
import tempfile
import io
import PyPDF2
import uuid
import threading
import base64
from datetime import datetime
from openai import OpenAI
from reportlab.lib.pagesizes import letter
from reportlab.lib.styles import getSampleStyleSheet, ParagraphStyle
from reportlab.lib.units import inch
from reportlab.platypus import SimpleDocTemplate, Paragraph, Spacer, PageBreak, Table, TableStyle
from reportlab.lib.enums import TA_JUSTIFY, TA_LEFT, TA_CENTER
from reportlab.lib import colors
from reportlab.pdfbase import pdfmetrics
from reportlab.pdfbase.ttfonts import TTFont
from dotenv import load_dotenv

load_dotenv()

# C·∫•u h√¨nh API
OPENAI_API_KEY = os.getenv('OPENAI_API_KEY')
client = OpenAI(api_key=OPENAI_API_KEY)

# L∆∞u tr·ªØ tr·∫°ng th√°i c√°c job trong b·ªô nh·ªõ
pdf_job_storage = {}

def tr√≠ch_xu·∫•t_text_t·ª´_pdf(pdf_path):
    """Tr√≠ch xu·∫•t n·ªôi dung text t·ª´ file PDF"""
    text = ""
    try:
        with open(pdf_path, 'rb') as file:
            pdf_reader = PyPDF2.PdfReader(file)
            num_pages = len(pdf_reader.pages)
            
            # Tr√≠ch xu·∫•t text t·ª´ t·∫•t c·∫£ c√°c trang
            for page_num in range(num_pages):
                page = pdf_reader.pages[page_num]
                text += page.extract_text() + "\n\n"
            
            print(f"‚úì ƒê√£ tr√≠ch xu·∫•t text t·ª´ {num_pages} trang")
    except Exception as e:
        print(f"L·ªói khi tr√≠ch xu·∫•t PDF: {str(e)}")
        raise
    
    return text

def ph√¢n_t√≠ch_v·ªõi_ai(text):
    """S·ª≠ d·ª•ng OpenAI ƒë·ªÉ ph√¢n t√≠ch t√†i li·ªáu h·ªçc thu·∫≠t v√† t·∫°o insights c√≥ c·∫•u tr√∫c"""
    try:
        # V√≠ d·ª• JSON m·∫´u
        example_json = """{
    "tieu_de": "·ª®ng d·ª•ng Machine Learning trong Ch·∫©n ƒëo√°n Y t·∫ø",
    "tom_tat": "B√†i b√°o n√†y kh√°m ph√° vi·ªác ·ª©ng d·ª•ng c√°c m√¥ h√¨nh deep learning trong ph√¢n t√≠ch h√¨nh ·∫£nh y t·∫ø. Nghi√™n c·ª©u ch·ª©ng minh r·∫±ng m·∫°ng neural t√≠ch ch·∫≠p c√≥ th·ªÉ ƒë·∫°t ƒë·ªô ch√≠nh x√°c 95% trong vi·ªác ph√°t hi·ªán ung th∆∞ giai ƒëo·∫°n ƒë·∫ßu. Nghi√™n c·ª©u cung c·∫•p m·ªôt framework ƒë·ªÉ t√≠ch h·ª£p AI v√†o quy tr√¨nh l√†m vi·ªác l√¢m s√†ng trong khi v·∫´n ƒë·∫£m b·∫£o an to√†n b·ªánh nh√¢n v√† quy·ªÅn ri√™ng t∆∞ d·ªØ li·ªáu.",
    "muc_tieu_hoc_tap": [
        "Hi·ªÉu c√°ch c√°c ki·∫øn tr√∫c deep learning x·ª≠ l√Ω d·ªØ li·ªáu h√¨nh ·∫£nh y t·∫ø",
        "ƒê√°nh gi√° hi·ªáu qu·∫£ c·ªßa transfer learning trong ·ª©ng d·ª•ng y t·∫ø",
        "Ph√¢n t√≠ch c√°c v·∫•n ƒë·ªÅ ƒë·∫°o ƒë·ª©c c·ªßa ch·∫©n ƒëo√°n y t·∫ø h·ªó tr·ª£ b·ªüi AI"
    ],
    "do_kho": "N√¢ng cao / Sau ƒë·∫°i h·ªçc",
    "thoi_gian_hoc_uoc_tinh": "45-60 ph√∫t",
    "thuat_ngu_chinh": {
        "M·∫°ng Neural T√≠ch ch·∫≠p (CNN)": "M·ªôt ki·∫øn tr√∫c deep learning ƒë∆∞·ª£c thi·∫øt k·∫ø ƒë·∫∑c bi·ªát ƒë·ªÉ x·ª≠ l√Ω d·ªØ li·ªáu d·∫°ng l∆∞·ªõi nh∆∞ h√¨nh ·∫£nh, s·ª≠ d·ª•ng c√°c l·ªõp t√≠ch ch·∫≠p ƒë·ªÉ ph√°t hi·ªán c√°c m·∫´u.",
        "Transfer Learning": "M·ªôt k·ªπ thu·∫≠t machine learning trong ƒë√≥ m·ªôt m√¥ h√¨nh ƒë∆∞·ª£c hu·∫•n luy·ªán tr√™n m·ªôt t√°c v·ª• ƒë∆∞·ª£c t√°i s·ª≠ d·ª•ng cho m·ªôt t√°c v·ª• li√™n quan th·ª© hai, gi·∫£m th·ªùi gian hu·∫•n luy·ªán v√† y√™u c·∫ßu d·ªØ li·ªáu.",
        "Cross-validation": "M·ªôt ph∆∞∆°ng ph√°p th·ªëng k√™ ƒë·ªÉ ƒë√°nh gi√° hi·ªáu su·∫•t m√¥ h√¨nh b·∫±ng c√°ch chia d·ªØ li·ªáu th√†nh c√°c t·∫≠p hu·∫•n luy·ªán v√† ki·ªÉm tra nhi·ªÅu l·∫ßn."
    },
    "phat_hien_chinh": [
        "M√¥ h√¨nh deep learning ƒë·∫°t ƒë·ªô ch√≠nh x√°c 95% trong ph√°t hi·ªán ung th∆∞ t·ª´ h√¨nh ·∫£nh CT",
        "Framework ƒë∆∞·ª£c ƒë·ªÅ xu·∫•t gi·∫£m th·ªùi gian ch·∫©n ƒëo√°n 40% so v·ªõi ph√¢n t√≠ch th·ªß c√¥ng",
        "Transfer learning t·ª´ c√°c m√¥ h√¨nh ƒë√£ ƒë∆∞·ª£c hu·∫•n luy·ªán tr∆∞·ªõc c·∫£i thi·ªán ƒë√°ng k·ªÉ hi·ªáu su·∫•t tr√™n t·∫≠p d·ªØ li·ªáu nh·ªè",
        "H·ªá th·ªëng duy tr√¨ hi·ªáu su·∫•t cao tr√™n c√°c nh√≥m nh√¢n kh·∫©u h·ªçc kh√°c nhau",
        "Vi·ªác t√≠ch h·ª£p v·ªõi h·ªá th·ªëng b·ªánh vi·ªán hi·ªán c√≥ l√† kh·∫£ thi v·ªõi s·ª± gi√°n ƒëo·∫°n quy tr√¨nh l√†m vi·ªác t·ªëi thi·ªÉu"
    ],
    "phuong_phap_nghien_cuu": "C√°c nh√† nghi√™n c·ª©u s·ª≠ d·ª•ng t·∫≠p d·ªØ li·ªáu 50,000 h√¨nh ·∫£nh y t·∫ø ƒë√£ ƒë∆∞·ª£c g√°n nh√£n ƒë·ªÉ hu·∫•n luy·ªán m·ªôt m·∫°ng neural t√≠ch ch·∫≠p d·ª±a tr√™n ResNet. H·ªç s·ª≠ d·ª•ng transfer learning, data augmentation v√† cross-validation ƒë·ªÉ ƒë·∫£m b·∫£o t√≠nh m·∫°nh m·∫Ω c·ªßa m√¥ h√¨nh. X√°c th·ª±c l√¢m s√†ng ƒë∆∞·ª£c th·ª±c hi·ªán th√¥ng qua m·ªôt nghi√™n c·ª©u ti·∫øn c·ª©u v·ªõi 500 b·ªánh nh√¢n.",
    "y_nghia": "Nghi√™n c·ª©u n√†y ch·ª©ng minh r·∫±ng ch·∫©n ƒëo√°n h·ªó tr·ª£ b·ªüi AI c√≥ th·ªÉ c·∫£i thi·ªán ƒë√°ng k·ªÉ k·∫øt qu·∫£ y t·∫ø b·∫±ng c√°ch cung c·∫•p ch·∫©n ƒëo√°n nhanh h∆°n v√† ch√≠nh x√°c h∆°n. Framework c√≥ th·ªÉ ƒë∆∞·ª£c ƒëi·ªÅu ch·ªânh cho c√°c t√°c v·ª• h√¨nh ·∫£nh y t·∫ø kh√°c v√† c√≥ ti·ªÅm nƒÉng gi·∫£m chi ph√≠ y t·∫ø trong khi c·∫£i thi·ªán chƒÉm s√≥c b·ªánh nh√¢n, ƒë·∫∑c bi·ªát trong c√°c m√¥i tr∆∞·ªùng y t·∫ø h·∫°n ch·∫ø t√†i nguy√™n.",
    "ung_dung_thuc_te": [
        "Ph√°t hi·ªán ung th∆∞ s·ªõm trong c√°c khoa X quang",
        "S√†ng l·ªçc t·ª± ƒë·ªông trong c√°c c∆° s·ªü y t·∫ø h·∫°n ch·∫ø t√†i nguy√™n",
        "H·ªá th·ªëng t∆∞ v·∫•n th·ª© hai ƒë·ªÉ gi·∫£m l·ªói ch·∫©n ƒëo√°n",
        "C√¥ng c·ª• ƒë√†o t·∫°o cho sinh vi√™n y khoa v√† b√°c sƒ© n·ªôi tr√∫"
    ],
    "cau_hoi_tu_duy_phe_phan": [
        "R·ªßi ro ti·ªÅm ·∫©n c·ªßa vi·ªác qu√° ph·ª• thu·ªôc v√†o h·ªá th·ªëng ch·∫©n ƒëo√°n AI trong th·ª±c h√†nh l√¢m s√†ng l√† g√¨?",
        "L√†m th·∫ø n√†o c√°c bias v·ªÅ nh√¢n kh·∫©u h·ªçc trong d·ªØ li·ªáu hu·∫•n luy·ªán c√≥ th·ªÉ ·∫£nh h∆∞·ªüng ƒë·∫øn hi·ªáu su·∫•t m√¥ h√¨nh tr√™n c√°c qu·∫ßn th·ªÉ b·ªánh nh√¢n kh√°c nhau?",
        "C·∫ßn c√≥ c√°c framework quy ƒë·ªãnh n√†o ƒë·ªÉ ƒë·∫£m b·∫£o an to√†n b·ªánh nh√¢n khi tri·ªÉn khai c√°c c√¥ng c·ª• ch·∫©n ƒëo√°n AI?"
    ],
    "cau_hoi_on_tap": [
        {
            "cau_hoi": "Ki·∫øn tr√∫c deep learning n√†o ƒë∆∞·ª£c s·ª≠ d·ª•ng trong nghi√™n c·ª©u n√†y?",
            "tra_loi": "M·∫°ng Neural T√≠ch ch·∫≠p (CNN) d·ª±a tr√™n ResNet",
            "do_kho": "D·ªÖ"
        },
        {
            "cau_hoi": "Transfer learning ƒë√£ c·∫£i thi·ªán hi·ªáu su·∫•t c·ªßa m√¥ h√¨nh nh∆∞ th·∫ø n√†o?",
            "tra_loi": "Transfer learning c·∫£i thi·ªán ƒë√°ng k·ªÉ hi·ªáu su·∫•t tr√™n t·∫≠p d·ªØ li·ªáu nh·ªè b·∫±ng c√°ch t·∫≠n d·ª•ng ki·∫øn th·ª©c t·ª´ c√°c m√¥ h√¨nh ƒë√£ ƒë∆∞·ª£c hu·∫•n luy·ªán tr∆∞·ªõc, gi·∫£m nhu c·∫ßu v·ªÅ d·ªØ li·ªáu hu·∫•n luy·ªán r·ªông r√£i.",
            "do_kho": "Trung b√¨nh"
        },
        {
            "cau_hoi": "Ph√¢n t√≠ch s·ª± ƒë√°nh ƒë·ªïi gi·ªØa t·ªëc ƒë·ªô ch·∫©n ƒëo√°n v√† ƒë·ªô ch√≠nh x√°c trong h√¨nh ·∫£nh y t·∫ø h·ªó tr·ª£ b·ªüi AI.",
            "tra_loi": "Trong khi h·ªá th·ªëng ƒë·∫°t ƒë∆∞·ª£c ch·∫©n ƒëo√°n nhanh h∆°n 40% v√† duy tr√¨ ƒë·ªô ch√≠nh x√°c 95%, c√≥ s·ª± c√¢n b·∫±ng gi·ªØa l·ª£i √≠ch v·ªÅ t·ªëc ƒë·ªô v√† ƒë·∫£m b·∫£o th·ªùi gian xem x√©t ƒë·ªß cho c√°c tr∆∞·ªùng h·ª£p ph·ª©c t·∫°p. H·ªá th·ªëng n√™n b·ªï sung ch·ª© kh√¥ng ph·∫£i thay th·∫ø chuy√™n m√¥n c·ªßa con ng∆∞·ªùi, ƒë·∫∑c bi·ªát cho c√°c tr∆∞·ªùng h·ª£p bi√™n.",
            "do_kho": "Kh√≥"
        }
    ],
    "ban_do_tu_duy": {
        "khai_niem_trung_tam": "Ch·∫©n ƒëo√°n Y t·∫ø H·ªó tr·ª£ AI",
        "nhanh": [
            {
                "chu_de": "Ph∆∞∆°ng ph√°p K·ªπ thu·∫≠t",
                "diem": ["Ki·∫øn tr√∫c deep learning", "Chi·∫øn l∆∞·ª£c transfer learning", "K·ªπ thu·∫≠t data augmentation"],
                "mau": "blue"
            },
            {
                "chu_de": "Hi·ªáu su·∫•t L√¢m s√†ng",
                "diem": ["ƒê·ªô ch√≠nh x√°c ph√°t hi·ªán 95%", "Ch·∫©n ƒëo√°n nhanh h∆°n 40%", "ƒê·ªô tin c·∫≠y xuy√™n nh√¢n kh·∫©u h·ªçc"],
                "mau": "green"
            },
            {
                "chu_de": "Tri·ªÉn khai",
                "diem": ["T√≠ch h·ª£p h·ªá th·ªëng b·ªánh vi·ªán", "T·ªëi ∆∞u h√≥a quy tr√¨nh", "B·∫£o v·ªá quy·ªÅn ri√™ng t∆∞"],
                "mau": "orange"
            },
            {
                "chu_de": "C√¢n nh·∫Øc ƒê·∫°o ƒë·ª©c",
                "diem": ["Bias thu·∫≠t to√°n", "S·ª± ƒë·ªìng √Ω c·ªßa b·ªánh nh√¢n", "Tu√¢n th·ªß quy ƒë·ªãnh"],
                "mau": "red"
            }
        ]
    },
    "tom_tat_truc_quan": {
        "quy_trinh": [
            "Thu th·∫≠p H√¨nh ·∫£nh ‚Üí Ti·ªÅn x·ª≠ l√Ω D·ªØ li·ªáu ‚Üí Hu·∫•n luy·ªán CNN ‚Üí X√°c th·ª±c ‚Üí Tri·ªÉn khai L√¢m s√†ng"
        ],
        "chi_so_chinh": {
            "ƒê·ªô ch√≠nh x√°c": "95%",
            "C·∫£i thi·ªán T·ªëc ƒë·ªô": "40%",
            "K√≠ch th∆∞·ªõc D·ªØ li·ªáu": "50,000 h√¨nh ·∫£nh"
        }
    }
}"""
        
        prompt = f"""B·∫°n l√† m·ªôt chuy√™n gia ph√¢n t√≠ch nghi√™n c·ª©u h·ªçc thu·∫≠t. H√£y ph√¢n t√≠ch t√†i li·ªáu h·ªçc thu·∫≠t sau ƒë√¢y v√† cung c·∫•p m·ªôt b·∫£n t·ªïng h·ª£p ki·∫øn th·ª©c to√†n di·ªán B·∫∞NG TI·∫æNG VI·ªÜT.

N·ªôi dung T√†i li·ªáu H·ªçc thu·∫≠t:
{text[:15000]}

H∆Ø·ªöNG D·∫™N QUAN TR·ªåNG:
1. B·∫°n PH·∫¢I tr·∫£ l·ªùi ch·ªâ v·ªõi JSON h·ª£p l·ªá - kh√¥ng c√≥ vƒÉn b·∫£n gi·∫£i th√≠ch tr∆∞·ªõc ho·∫∑c sau
2. Tu√¢n theo C·∫§U TR√öC CH√çNH X√ÅC n√†y (ƒë√¢y l√† v√≠ d·ª• ho√†n ch·ªânh):

{example_json}

3. Ph·∫£n h·ªìi c·ªßa b·∫°n ph·∫£i b·∫Øt ƒë·∫ßu b·∫±ng {{ v√† k·∫øt th√∫c b·∫±ng }}
4. ƒê·∫£m b·∫£o t·∫•t c·∫£ c√°c chu·ªói ƒë∆∞·ª£c escape v√† quote ƒë√∫ng c√°ch
5. Kh√¥ng bao g·ªìm b·∫•t k·ª≥ ƒë·ªãnh d·∫°ng markdown, code blocks ho·∫∑c gi·∫£i th√≠ch n√†o
6. T·∫§T C·∫¢ n·ªôi dung ph·∫£i b·∫±ng TI·∫æNG VI·ªÜT

B√¢y gi·ªù h√£y ph√¢n t√≠ch t√†i li·ªáu h·ªçc thu·∫≠t ·ªü tr√™n v√† cung c·∫•p ph·∫£n h·ªìi c·ªßa b·∫°n theo CH√çNH X√ÅC ƒë·ªãnh d·∫°ng JSON nh∆∞ v√≠ d·ª•."""

        response = client.chat.completions.create(
            model="gpt-4o-mini",
            messages=[
                {"role": "system", "content": "B·∫°n l√† m·ªôt chuy√™n gia ph√¢n t√≠ch nghi√™n c·ª©u h·ªçc thu·∫≠t. B·∫°n PH·∫¢I tr·∫£ l·ªùi ch·ªâ v·ªõi JSON h·ª£p l·ªá B·∫∞NG TI·∫æNG VI·ªÜT. Kh√¥ng bao g·ªìm b·∫•t k·ª≥ vƒÉn b·∫£n n√†o tr∆∞·ªõc ho·∫∑c sau JSON. Kh√¥ng s·ª≠ d·ª•ng markdown code blocks. B·∫Øt ƒë·∫ßu ph·∫£n h·ªìi c·ªßa b·∫°n b·∫±ng { v√† k·∫øt th√∫c b·∫±ng }."},
                {"role": "user", "content": prompt}
            ],
            temperature=0.7
        )
        
        content = response.choices[0].message.content.strip()
        
        # Log response for debugging
        print(f"Raw AI response (first 200 chars): {content[:200]}")
        
        # Remove markdown code blocks if present
        if content.startswith("```json"):
            content = content[7:]
        if content.startswith("```"):
            content = content[3:]
        if content.endswith("```"):
            content = content[:-3]
        
        content = content.strip()
        
        # Check if response is empty
        if not content:
            raise Exception("AI tr·∫£ v·ªÅ ph·∫£n h·ªìi r·ªóng")
        
        # Check if response starts with valid JSON
        if not content.startswith("{"):
            print(f"C·∫£nh b√°o: Ph·∫£n h·ªìi kh√¥ng b·∫Øt ƒë·∫ßu b·∫±ng '{{'. First 100 chars: {content[:100]}")
            json_start = content.find("{")
            if json_start != -1:
                content = content[json_start:]
                print(f"ƒê√£ tr√≠ch xu·∫•t JSON b·∫Øt ƒë·∫ßu t·ª´ v·ªã tr√≠ {json_start}")
            else:
                raise Exception(f"Kh√¥ng t√¨m th·∫•y JSON object trong ph·∫£n h·ªìi. Response: {content[:200]}")
        
        analysis = json.loads(content)
        print("‚úì Ph√¢n t√≠ch AI ho√†n t·∫•t th√†nh c√¥ng")
        return analysis
        
    except json.JSONDecodeError as e:
        print(f"L·ªói JSON decode: {str(e)}")
        print(f"Failed content (first 500 chars): {content[:500] if 'content' in locals() else 'Kh√¥ng c√≥ n·ªôi dung'}")
        raise Exception(f"Kh√¥ng th·ªÉ parse ph·∫£n h·ªìi AI th√†nh JSON: {str(e)}")
    except Exception as e:
        print(f"L·ªói trong ph√¢n t√≠ch AI: {str(e)}")
        raise Exception(f"Kh√¥ng th·ªÉ t·∫°o ph√¢n t√≠ch AI: {str(e)}")

def t·∫°o_pdf_flashcard(analysis, output_path):
    """T·∫°o PDF flashcard ki·∫øn th·ª©c gi√°o d·ª•c ƒë·∫πp v√† to√†n di·ªán"""
    try:
        # ƒêƒÉng k√Ω font Unicode h·ªó tr·ª£ ti·∫øng Vi·ªát
        # S·ª≠ d·ª•ng font Arial c√≥ s·∫µn tr√™n Windows
        try:
            # ƒê∆∞·ªùng d·∫´n font tr√™n Windows
            pdfmetrics.registerFont(TTFont('Arial', 'C:/Windows/Fonts/arial.ttf'))
            pdfmetrics.registerFont(TTFont('Arial-Bold', 'C:/Windows/Fonts/arialbd.ttf'))
            pdfmetrics.registerFont(TTFont('Arial-Italic', 'C:/Windows/Fonts/ariali.ttf'))
            font_name = 'Arial'
            font_bold = 'Arial-Bold'
            font_italic = 'Arial-Italic'
        except:
            # Fallback to default if Arial not found
            font_name = 'Helvetica'
            font_bold = 'Helvetica-Bold'
            font_italic = 'Helvetica-Oblique'
        
        doc = SimpleDocTemplate(output_path, pagesize=letter,
                                rightMargin=60, leftMargin=60,
                                topMargin=60, bottomMargin=40)
        
        elements = []
        styles = getSampleStyleSheet()
        
        # ============= C√ÅC STYLE T√ôY CH·ªàNH =============
        title_style = ParagraphStyle(
            'CustomTitle',
            parent=styles['Heading1'],
            fontSize=26,
            textColor=colors.HexColor('#1a237e'),
            spaceAfter=10,
            spaceBefore=20,
            alignment=TA_CENTER,
            fontName=font_bold
        )
        
        subtitle_style = ParagraphStyle(
            'Subtitle',
            parent=styles['Normal'],
            fontSize=11,
            textColor=colors.HexColor('#5e35b1'),
            spaceAfter=20,
            alignment=TA_CENTER,
            fontName=font_italic
        )
        
        section_header_style = ParagraphStyle(
            'SectionHeader',
            parent=styles['Heading2'],
            fontSize=18,
            textColor=colors.white,
            spaceAfter=15,
            spaceBefore=20,
            fontName=font_bold,
            backColor=colors.HexColor('#1976d2'),
            borderPadding=(8, 8, 8, 8),
            leftIndent=10
        )
        
        body_style = ParagraphStyle(
            'CustomBody',
            parent=styles['BodyText'],
            fontSize=11,
            textColor=colors.HexColor('#212121'),
            spaceAfter=12,
            alignment=TA_JUSTIFY,
            leading=16,
            fontName=font_name
        )
        
        highlight_style = ParagraphStyle(
            'Highlight',
            parent=styles['BodyText'],
            fontSize=11,
            textColor=colors.HexColor('#1565c0'),
            spaceAfter=10,
            leftIndent=15,
            rightIndent=15,
            backColor=colors.HexColor('#e3f2fd'),
            borderColor=colors.HexColor('#1976d2'),
            borderWidth=1,
            borderPadding=10,
            leading=15,
            fontName=font_name
        )
        
        term_style = ParagraphStyle(
            'Term',
            parent=styles['BodyText'],
            fontSize=10,
            textColor=colors.HexColor('#2e7d32'),
            spaceAfter=8,
            leftIndent=20,
            leading=13,
            fontName=font_bold
        )
        
        definition_style = ParagraphStyle(
            'Definition',
            parent=styles['BodyText'],
            fontSize=10,
            textColor=colors.HexColor('#424242'),
            spaceAfter=10,
            leftIndent=35,
            leading=13,
            fontName=font_name
        )
        
        subsection_style = ParagraphStyle(
            'Subsection',
            parent=styles['Heading3'],
            fontSize=14,
            textColor=colors.HexColor('#0277bd'),
            spaceAfter=10,
            spaceBefore=12,
            fontName=font_bold
        )
        
        question_style = ParagraphStyle(
            'Question',
            parent=styles['BodyText'],
            fontSize=10,
            textColor=colors.HexColor('#d32f2f'),
            spaceAfter=6,
            fontName=font_bold,
            leftIndent=15
        )
        
        answer_style = ParagraphStyle(
            'Answer',
            parent=styles['BodyText'],
            fontSize=10,
            textColor=colors.HexColor('#424242'),
            spaceAfter=12,
            leftIndent=25,
            leading=13,
            fontName=font_name
        )
        
        # ============= TRANG B√åA =============
        elements.append(Spacer(1, 40))
        
        # Thanh trang tr√≠ tr√™n c√πng
        top_bar = Table([['']], colWidths=[doc.width])
        top_bar.setStyle(TableStyle([
            ('BACKGROUND', (0, 0), (-1, -1), colors.HexColor('#1976d2')),
            ('LINEBELOW', (0, 0), (-1, -1), 4, colors.HexColor('#0d47a1'))
        ]))
        elements.append(top_bar)
        elements.append(Spacer(1, 30))
        
        # Ti√™u ƒë·ªÅ
        title = Paragraph(f"<b>{analysis['tieu_de']}</b>", title_style)
        elements.append(title)
        
        # H·ªôp metadata
        metadata_text = f"""<b>ƒê·ªô kh√≥:</b> {analysis.get('do_kho', 'Trung b√¨nh')} | 
        <b>Th·ªùi gian h·ªçc:</b> {analysis.get('thoi_gian_hoc_uoc_tinh', '30-45 ph√∫t')}"""
        elements.append(Paragraph(metadata_text, subtitle_style))
        elements.append(Spacer(1, 20))
        
        # H·ªôp m·ª•c ti√™u h·ªçc t·∫≠p
        if analysis.get('muc_tieu_hoc_tap'):
            obj_data = [[Paragraph("<b>üéØ M·ª•c ti√™u H·ªçc t·∫≠p</b>", body_style)]]
            for obj in analysis['muc_tieu_hoc_tap']:
                obj_data.append([Paragraph(f"‚Ä¢ {obj}", body_style)])
            
            obj_table = Table(obj_data, colWidths=[doc.width])
            obj_table.setStyle(TableStyle([
                ('BACKGROUND', (0, 0), (-1, 0), colors.HexColor('#e8f5e9')),
                ('BACKGROUND', (0, 1), (-1, -1), colors.HexColor('#f1f8e9')),
                ('BOX', (0, 0), (-1, -1), 2, colors.HexColor('#388e3c')),
                ('LEFTPADDING', (0, 0), (-1, -1), 12),
                ('RIGHTPADDING', (0, 0), (-1, -1), 12),
                ('TOPPADDING', (0, 0), (-1, -1), 8),
                ('BOTTOMPADDING', (0, 0), (-1, -1), 8),
            ]))
            elements.append(obj_table)
            elements.append(Spacer(1, 20))
        
        # ============= T√ìM T·∫ÆT T·ªîNG QUAN =============
        elements.append(Paragraph("üìã T√≥m t·∫Øt T·ªïng quan", section_header_style))
        elements.append(Spacer(1, 5))
        
        summary_text = analysis['tom_tat']
        if isinstance(summary_text, list):
            summary_text = ' '.join(summary_text)
        
        elements.append(Paragraph(summary_text, highlight_style))
        elements.append(Spacer(1, 15))
        
        # ============= CH·ªà S·ªê CH√çNH =============
        if analysis.get('tom_tat_truc_quan', {}).get('chi_so_chinh'):
            metrics = analysis['tom_tat_truc_quan']['chi_so_chinh']
            elements.append(Paragraph("üìä Ch·ªâ s·ªë Ch√≠nh Nhanh", body_style))
            
            metric_data = []
            for key, value in metrics.items():
                metric_data.append([
                    Paragraph(f"<b>{key}</b>", body_style),
                    Paragraph(f"<font size=14 color='#1976d2'><b>{value}</b></font>", body_style)
                ])
            
            metric_table = Table(metric_data, colWidths=[doc.width * 0.6, doc.width * 0.4])
            metric_table.setStyle(TableStyle([
                ('BACKGROUND', (0, 0), (-1, -1), colors.HexColor('#e3f2fd')),
                ('GRID', (0, 0), (-1, -1), 1, colors.HexColor('#1976d2')),
                ('ALIGN', (1, 0), (1, -1), 'CENTER'),
                ('VALIGN', (0, 0), (-1, -1), 'MIDDLE'),
                ('LEFTPADDING', (0, 0), (-1, -1), 10),
                ('RIGHTPADDING', (0, 0), (-1, -1), 10),
                ('TOPPADDING', (0, 0), (-1, -1), 8),
                ('BOTTOMPADDING', (0, 0), (-1, -1), 8),
            ]))
            elements.append(metric_table)
            elements.append(Spacer(1, 20))
        
        # ============= PH√ÅT HI·ªÜN CH√çNH =============
        elements.append(Paragraph("üí° Ph√°t hi·ªán Ch√≠nh", section_header_style))
        elements.append(Spacer(1, 5))
        
        findings_data = []
        for i, finding in enumerate(analysis['phat_hien_chinh'], 1):
            if i <= 2:
                bg_color = colors.HexColor('#fff3e0')
            else:
                bg_color = colors.white
            
            findings_data.append([
                Paragraph(f"<b>{i}</b>", body_style),
                Paragraph(finding, body_style)
            ])
        
        findings_table = Table(findings_data, colWidths=[30, doc.width - 30])
        findings_table.setStyle(TableStyle([
            ('BACKGROUND', (0, 0), (0, 1), colors.HexColor('#ff9800')),
            ('BACKGROUND', (1, 0), (1, 1), colors.HexColor('#fff3e0')),
            ('BACKGROUND', (0, 2), (-1, -1), colors.white),
            ('TEXTCOLOR', (0, 0), (0, -1), colors.white),
            ('ALIGN', (0, 0), (0, -1), 'CENTER'),
            ('VALIGN', (0, 0), (-1, -1), 'MIDDLE'),
            ('FONTNAME', (0, 0), (0, -1), font_bold),
            ('FONTSIZE', (0, 0), (0, -1), 12),
            ('GRID', (0, 0), (-1, -1), 1, colors.HexColor('#e0e0e0')),
            ('LEFTPADDING', (0, 0), (-1, -1), 10),
            ('RIGHTPADDING', (0, 0), (-1, -1), 10),
            ('TOPPADDING', (0, 0), (-1, -1), 8),
            ('BOTTOMPADDING', (0, 0), (-1, -1), 8),
        ]))
        elements.append(findings_table)
        elements.append(Spacer(1, 20))
        
        # ============= THU·∫¨T NG·ªÆ & ƒê·ªäNH NGHƒ®A =============
        if analysis.get('thuat_ngu_chinh'):
            elements.append(PageBreak())
            elements.append(Paragraph("üìö Thu·∫≠t ng·ªØ & ƒê·ªãnh nghƒ©a Ch√≠nh", section_header_style))
            elements.append(Spacer(1, 10))
            
            for term, definition in analysis['thuat_ngu_chinh'].items():
                elements.append(Paragraph(f"<b>‚ñ∏ {term}</b>", term_style))
                elements.append(Paragraph(definition, definition_style))
            
            elements.append(Spacer(1, 20))
        
        # ============= PH∆Ø∆†NG PH√ÅP =============
        elements.append(Paragraph("üî¨ Ph∆∞∆°ng ph√°p Nghi√™n c·ª©u", section_header_style))
        elements.append(Spacer(1, 5))
        
        methodology_text = analysis['phuong_phap_nghien_cuu']
        if isinstance(methodology_text, list):
            methodology_text = ' '.join(methodology_text)
        
        elements.append(Paragraph(methodology_text, body_style))
        elements.append(Spacer(1, 20))
        
        # ============= ·ª®NG D·ª§NG TH·ª∞C T·∫æ =============
        if analysis.get('ung_dung_thuc_te'):
            elements.append(Paragraph("üåç ·ª®ng d·ª•ng Th·ª±c t·∫ø", section_header_style))
            elements.append(Spacer(1, 5))
            
            app_data = []
            for app in analysis['ung_dung_thuc_te']:
                app_data.append([
                    Paragraph("‚úì", body_style),
                    Paragraph(app, body_style)
                ])
            
            app_table = Table(app_data, colWidths=[30, doc.width - 30])
            app_table.setStyle(TableStyle([
                ('BACKGROUND', (0, 0), (-1, -1), colors.HexColor('#e8f5e9')),
                ('TEXTCOLOR', (0, 0), (0, -1), colors.HexColor('#2e7d32')),
                ('FONTSIZE', (0, 0), (0, -1), 14),
                ('FONTNAME', (0, 0), (0, -1), font_bold),
                ('VALIGN', (0, 0), (-1, -1), 'MIDDLE'),
                ('LEFTPADDING', (0, 0), (-1, -1), 10),
                ('RIGHTPADDING', (0, 0), (-1, -1), 10),
                ('TOPPADDING', (0, 0), (-1, -1), 8),
                ('BOTTOMPADDING', (0, 0), (-1, -1), 8),
            ]))
            elements.append(app_table)
            elements.append(Spacer(1, 20))
        
        # ============= √ù NGHƒ®A =============
        elements.append(Paragraph("üéì √ù nghƒ©a Ch√≠nh", section_header_style))
        elements.append(Spacer(1, 5))
        
        implications_text = analysis['y_nghia']
        if isinstance(implications_text, list):
            implications_text = ' '.join(implications_text)
        
        elements.append(Paragraph(implications_text, highlight_style))
        elements.append(Spacer(1, 20))
        
        # ============= C√ÇU H·ªéI T∆Ø DUY PH√ä PH√ÅN =============
        if analysis.get('cau_hoi_tu_duy_phe_phan'):
            elements.append(PageBreak())
            elements.append(Paragraph("ü§î C√¢u h·ªèi T∆∞ duy Ph√™ ph√°n", section_header_style))
            elements.append(Spacer(1, 10))
            
            crit_data = [[Paragraph("<i>Suy ng·∫´m v·ªÅ nh·ªØng c√¢u h·ªèi n√†y ƒë·ªÉ hi·ªÉu s√¢u h∆°n:</i>", body_style)]]
            for i, q in enumerate(analysis['cau_hoi_tu_duy_phe_phan'], 1):
                crit_data.append([Paragraph(f"<b>{i}.</b> {q}", body_style)])
            
            crit_table = Table(crit_data, colWidths=[doc.width])
            crit_table.setStyle(TableStyle([
                ('BACKGROUND', (0, 0), (-1, 0), colors.HexColor('#fff3e0')),
                ('BACKGROUND', (0, 1), (-1, -1), colors.white),
                ('BOX', (0, 0), (-1, -1), 2, colors.HexColor('#f57c00')),
                ('LINEBELOW', (0, 0), (-1, 0), 1, colors.HexColor('#f57c00')),
                ('LEFTPADDING', (0, 0), (-1, -1), 15),
                ('RIGHTPADDING', (0, 0), (-1, -1), 15),
                ('TOPPADDING', (0, 0), (-1, -1), 10),
                ('BOTTOMPADDING', (0, 0), (-1, -1), 10),
            ]))
            elements.append(crit_table)
            elements.append(Spacer(1, 25))
        
        # ============= C√ÇU H·ªéI √îN T·∫¨P =============
        if analysis.get('cau_hoi_on_tap'):
            elements.append(Paragraph("‚úèÔ∏è C√¢u h·ªèi T·ª± ƒë√°nh gi√°", section_header_style))
            elements.append(Spacer(1, 10))
            
            for i, qa in enumerate(analysis['cau_hoi_on_tap'], 1):
                difficulty = qa.get('do_kho', 'Trung b√¨nh')
                
                if difficulty == 'D·ªÖ':
                    diff_color = '#4caf50'
                    bg_color = '#e8f5e9'
                elif difficulty == 'Kh√≥':
                    diff_color = '#f44336'
                    bg_color = '#ffebee'
                else:
                    diff_color = '#ff9800'
                    bg_color = '#fff3e0'
                
                # H·ªôp c√¢u h·ªèi
                q_data = [
                    [Paragraph(f"<b>C√¢u h·ªèi {i}</b> <font color='{diff_color}'>[{difficulty}]</font>", body_style)],
                    [Paragraph(qa['cau_hoi'], body_style)]
                ]
                
                q_table = Table(q_data, colWidths=[doc.width])
                q_table.setStyle(TableStyle([
                    ('BACKGROUND', (0, 0), (-1, -1), colors.HexColor(bg_color)),
                    ('BOX', (0, 0), (-1, -1), 1.5, colors.HexColor(diff_color)),
                    ('LEFTPADDING', (0, 0), (-1, -1), 12),
                    ('RIGHTPADDING', (0, 0), (-1, -1), 12),
                    ('TOPPADDING', (0, 0), (-1, -1), 8),
                    ('BOTTOMPADDING', (0, 0), (-1, -1), 8),
                ]))
                elements.append(q_table)
                elements.append(Spacer(1, 8))
                
                # H·ªôp tr·∫£ l·ªùi
                answer_style = ParagraphStyle(
                    'Answer',
                    parent=styles['BodyText'],
                    fontName=font_name,
                    fontSize=10,
                    textColor=colors.HexColor('#424242'),
                    spaceAfter=12,
                    leftIndent=25,
                    leading=13
                )
                a_data = [[Paragraph(f"<b>Tr·∫£ l·ªùi:</b> {qa['tra_loi']}", answer_style)]]
                a_table = Table(a_data, colWidths=[doc.width])
                a_table.setStyle(TableStyle([
                    ('BACKGROUND', (0, 0), (-1, -1), colors.HexColor('#f5f5f5')),
                    ('BOX', (0, 0), (-1, -1), 1, colors.HexColor('#bdbdbd')),
                    ('LEFTPADDING', (0, 0), (-1, -1), 12),
                    ('RIGHTPADDING', (0, 0), (-1, -1), 12),
                    ('TOPPADDING', (0, 0), (-1, -1), 8),
                    ('BOTTOMPADDING', (0, 0), (-1, -1), 8),
                ]))
                elements.append(a_table)
                elements.append(Spacer(1, 15))
        
        # ============= B·∫¢N ƒê·ªí T∆Ø DUY =============
        elements.append(PageBreak())
        elements.append(Paragraph("üó∫Ô∏è B·∫£n ƒë·ªì T∆∞ duy Kh√°i ni·ªám", section_header_style))
        elements.append(Spacer(1, 15))
        
        # Kh√°i ni·ªám trung t√¢m
        central = analysis['ban_do_tu_duy']['khai_niem_trung_tam']
        central_data = [[Paragraph(f"<b>{central}</b>", 
            ParagraphStyle('Central', parent=body_style, fontSize=14, 
                          alignment=TA_CENTER, textColor=colors.white))]]
        
        central_table = Table(central_data, colWidths=[doc.width * 0.6])
        central_table.setStyle(TableStyle([
            ('BACKGROUND', (0, 0), (-1, -1), colors.HexColor('#1976d2')),
            ('ALIGN', (0, 0), (-1, -1), 'CENTER'),
            ('VALIGN', (0, 0), (-1, -1), 'MIDDLE'),
            ('LEFTPADDING', (0, 0), (-1, -1), 15),
            ('RIGHTPADDING', (0, 0), (-1, -1), 15),
            ('TOPPADDING', (0, 0), (-1, -1), 12),
            ('BOTTOMPADDING', (0, 0), (-1, -1), 12),
            ('BOX', (0, 0), (-1, -1), 3, colors.HexColor('#0d47a1')),
        ]))
        
        central_wrapper = Table([[central_table]], colWidths=[doc.width])
        central_wrapper.setStyle(TableStyle([
            ('ALIGN', (0, 0), (-1, -1), 'CENTER'),
            ('VALIGN', (0, 0), (-1, -1), 'MIDDLE'),
        ]))
        elements.append(central_wrapper)
        elements.append(Spacer(1, 20))
        
        # C√°c nh√°nh
        branch_colors = {
            'blue': '#1976d2',
            'green': '#388e3c',
            'orange': '#f57c00',
            'red': '#d32f2f',
            'purple': '#7b1fa2',
            'teal': '#00796b'
        }
        
        for i, branch in enumerate(analysis['ban_do_tu_duy']['nhanh']):
            color_name = branch.get('mau', list(branch_colors.keys())[i % len(branch_colors)])
            branch_color = branch_colors.get(color_name, '#1976d2')
            
            branch_header = Table([[Paragraph(f"<b>{branch['chu_de']}</b>", 
                ParagraphStyle('BranchHeader', parent=body_style, 
                              textColor=colors.white, fontSize=12))]], 
                colWidths=[doc.width * 0.7])
            branch_header.setStyle(TableStyle([
                ('BACKGROUND', (0, 0), (-1, -1), colors.HexColor(branch_color)),
                ('LEFTPADDING', (0, 0), (-1, -1), 10),
                ('RIGHTPADDING', (0, 0), (-1, -1), 10),
                ('TOPPADDING', (0, 0), (-1, -1), 6),
                ('BOTTOMPADDING', (0, 0), (-1, -1), 6),
            ]))
            elements.append(branch_header)
            elements.append(Spacer(1, 5))
            
            for point in branch['diem']:
                point_text = Paragraph(f"  ‚Ä¢ {point}", body_style)
                elements.append(point_text)
            
            elements.append(Spacer(1, 15))
        
        # ============= M·∫∏O H·ªåC T·∫¨P =============
        elements.append(PageBreak())
        elements.append(Paragraph("üìÖ M·∫πo H·ªçc t·∫≠p & Chi·∫øn l∆∞·ª£c Ghi nh·ªõ", section_header_style))
        elements.append(Spacer(1, 10))
        
        tips_data = [
            ["üìñ", "<b>√în t·∫≠p L·∫ßn 1:</b> Trong v√≤ng 24 gi·ªù sau khi ƒë·ªçc flashcard n√†y"],
            ["üîÑ", "<b>√în t·∫≠p L·∫ßn 2:</b> 3 ng√†y sau l·∫ßn √¥n ƒë·∫ßu ti√™n"],
            ["‚úÖ", "<b>√în t·∫≠p L·∫ßn 3:</b> 1 tu·∫ßn sau l·∫ßn √¥n th·ª© hai"],
            ["üéØ", "<b>√în t·∫≠p Cu·ªëi:</b> 2 tu·∫ßn sau l·∫ßn √¥n th·ª© ba"],
            ["üí°", "<b>G·ª£i nh·ªõ Ch·ªß ƒë·ªông:</b> C·ªë tr·∫£ l·ªùi c√°c c√¢u h·ªèi m√† kh√¥ng nh√¨n ƒë√°p √°n tr∆∞·ªõc"],
            ["ü§ù", "<b>D·∫°y ng∆∞·ªùi kh√°c:</b> Gi·∫£i th√≠ch kh√°i ni·ªám cho ƒë·ªìng h·ªçc ƒë·ªÉ c·ªßng c·ªë hi·ªÉu bi·∫øt"],
        ]
        
        tips_table_data = []
        for emoji, tip in tips_data:
            tips_table_data.append([
                Paragraph(emoji, body_style),
                Paragraph(tip, body_style)
            ])
        
        tips_table = Table(tips_table_data, colWidths=[40, doc.width - 40])
        tips_table.setStyle(TableStyle([
            ('BACKGROUND', (0, 0), (-1, -1), colors.HexColor('#f3e5f5')),
            ('VALIGN', (0, 0), (-1, -1), 'MIDDLE'),
            ('LEFTPADDING', (0, 0), (-1, -1), 10),
            ('RIGHTPADDING', (0, 0), (-1, -1), 10),
            ('TOPPADDING', (0, 0), (-1, -1), 8),
            ('BOTTOMPADDING', (0, 0), (-1, -1), 8),
            ('LINEBELOW', (0, 0), (-1, -2), 1, colors.HexColor('#ce93d8')),
        ]))
        elements.append(tips_table)
        elements.append(Spacer(1, 20))
        
        # ============= FOOTER =============
        elements.append(Spacer(1, 30))
        footer_style = ParagraphStyle(
            'Footer',
            parent=styles['Normal'],
            fontSize=9,
            textColor=colors.HexColor('#757575'),
            alignment=TA_CENTER,
            fontName=font_name
        )
        
        footer_table = Table([
            [Paragraph("‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ", footer_style)],
            [Paragraph("<b>Nh√†n H·ªçc - Ph√¢n t√≠ch T√†i li·ªáu</b> | ƒê∆∞·ª£c h·ªó tr·ª£ b·ªüi AI", footer_style)],
            [Paragraph("H·ªçc th√¥ng minh, h·ªçc nhanh h∆°n, ghi nh·ªõ l√¢u h∆°n üöÄ", footer_style)]
        ], colWidths=[doc.width])
        footer_table.setStyle(TableStyle([
            ('ALIGN', (0, 0), (-1, -1), 'CENTER'),
        ]))
        elements.append(footer_table)
        
        # X√¢y d·ª±ng PDF
        doc.build(elements)
        print(f"‚úì PDF flashcard ki·∫øn th·ª©c n√¢ng cao ƒë√£ ƒë∆∞·ª£c t·∫°o th√†nh c√¥ng!")
        print(f"‚úì Output: {output_path}")
        
    except Exception as e:
        print(f"L·ªói khi t·∫°o PDF: {str(e)}")
        import traceback
        traceback.print_exc()
        raise

def x·ª≠_l√Ω_pdf_ƒë·ªìng_b·ªô(pdf_path, filename):
    """X·ª≠ l√Ω ph√¢n t√≠ch PDF ƒë·ªìng b·ªô - tr·∫£ v·ªÅ PDF content"""
    try:
        # B∆∞·ªõc 1: Tr√≠ch xu·∫•t text t·ª´ PDF
        print("ƒêang tr√≠ch xu·∫•t text t·ª´ PDF...")
        text = tr√≠ch_xu·∫•t_text_t·ª´_pdf(pdf_path)
        
        if len(text.strip()) < 100:
            raise Exception('PDF c√≥ v·∫ª r·ªóng ho·∫∑c kh√¥ng ƒë·ªçc ƒë∆∞·ª£c')
        
        # B∆∞·ªõc 2: Ph√¢n t√≠ch v·ªõi AI
        print("ƒêang ph√¢n t√≠ch n·ªôi dung v·ªõi AI...")
        analysis = ph√¢n_t√≠ch_v·ªõi_ai(text)
        
        # B∆∞·ªõc 3: T·∫°o PDF output
        print("ƒêang t·∫°o PDF flashcard...")
        with tempfile.NamedTemporaryFile(delete=False, suffix='.pdf') as temp_output:
            output_path = temp_output.name
        
        t·∫°o_pdf_flashcard(analysis, output_path)
        
        # ƒê·ªçc file PDF ƒë√£ t·∫°o
        with open(output_path, 'rb') as f:
            pdf_content = f.read()
        
        # Cleanup
        os.unlink(output_path)
        
        return pdf_content
        
    except Exception as e:
        print(f"L·ªói trong x·ª≠ l√Ω PDF: {str(e)}")
        raise e

def process_pdf_job(job_id, pdf_path, filename):
    """X·ª≠ l√Ω PDF job trong background thread"""
    try:
        print(f"[PDF Job {job_id}] B·∫Øt ƒë·∫ßu x·ª≠ l√Ω...")
        pdf_job_storage[job_id]['status'] = 'processing'
        pdf_job_storage[job_id]['updated_at'] = datetime.now().isoformat()
        
        # X·ª≠ l√Ω PDF
        pdf_content = x·ª≠_l√Ω_pdf_ƒë·ªìng_b·ªô(pdf_path, filename)
        
        # Encode PDF content th√†nh base64 ƒë·ªÉ l∆∞u tr·ªØ
        pdf_base64 = base64.b64encode(pdf_content).decode('utf-8')
        
        # C·∫≠p nh·∫≠t k·∫øt qu·∫£
        pdf_job_storage[job_id]['status'] = 'completed'
        pdf_job_storage[job_id]['result'] = {
            'pdf_content': pdf_base64,
            'filename': f'phan_tich_{filename}'
        }
        pdf_job_storage[job_id]['updated_at'] = datetime.now().isoformat()
        pdf_job_storage[job_id]['completed_at'] = datetime.now().isoformat()
        
        print(f"[PDF Job {job_id}] Ho√†n th√†nh!")
        
    except Exception as e:
        print(f"[PDF Job {job_id}] L·ªói: {str(e)}")
        pdf_job_storage[job_id]['status'] = 'failed'
        pdf_job_storage[job_id]['error'] = str(e)
        pdf_job_storage[job_id]['updated_at'] = datetime.now().isoformat()
    
    finally:
        # Cleanup PDF file
        try:
            if os.path.exists(pdf_path):
                os.unlink(pdf_path)
        except:
            pass

def ph√¢n_t√≠ch_pdf():
    """T·∫°o PDF job v√† tr·∫£ v·ªÅ job_id ngay l·∫≠p t·ª©c"""
    try:
        if 'file' not in request.files:
            return {'error': 'Kh√¥ng c√≥ file ƒë∆∞·ª£c upload'}, 400
        
        file = request.files['file']
        
        if file.filename == '':
            return {'error': 'Kh√¥ng c√≥ file ƒë∆∞·ª£c ch·ªçn'}, 400
        
        if not file.filename.endswith('.pdf'):
            return {'error': 'Ch·ªâ ch·∫•p nh·∫≠n file PDF'}, 400
        
        # L∆∞u file t·∫°m th·ªùi
        with tempfile.NamedTemporaryFile(delete=False, suffix='.pdf') as temp_pdf:
            file.save(temp_pdf.name)
            pdf_path = temp_pdf.name
        
        # T·∫°o job ID
        job_id = str(uuid.uuid4())
        
        # Kh·ªüi t·∫°o job
        pdf_job_storage[job_id] = {
            'job_id': job_id,
            'status': 'pending',
            'filename': file.filename,
            'created_at': datetime.now().isoformat(),
            'updated_at': datetime.now().isoformat(),
            'result': None,
            'error': None
        }
        
        # Ch·∫°y x·ª≠ l√Ω trong background thread
        thread = threading.Thread(
            target=process_pdf_job,
            args=(job_id, pdf_path, file.filename)
        )
        thread.daemon = True
        thread.start()
        
        print(f"[PDF Job {job_id}] ƒê√£ t·∫°o v√† b·∫Øt ƒë·∫ßu background processing")
        
        return {
            'job_id': job_id,
            'status': 'pending',
            'message': 'ƒêang ph√¢n t√≠ch PDF c·ªßa b·∫°n. Vui l√≤ng ƒë·ª£i...'
        }, 202
        
    except Exception as e:
        print(f"L·ªói: {str(e)}")
        import traceback
        traceback.print_exc()
        return {'error': str(e)}, 500

def get_pdf_job_status(job_id):
    """L·∫•y tr·∫°ng th√°i c·ªßa PDF job"""
    if job_id not in pdf_job_storage:
        return None
    return pdf_job_storage[job_id]
