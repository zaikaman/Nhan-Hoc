import os
from openai import OpenAI
import json
import uuid
import threading
from datetime import datetime
from dotenv import load_dotenv

load_dotenv()

client = OpenAI(
    api_key=os.environ.get("OPENAI_API_KEY"),
    base_url=os.environ.get("OPENAI_BASE_URL")
)

# L∆∞u tr·ªØ tr·∫°ng th√°i c√°c job trong b·ªô nh·ªõ
chat_job_storage = {}

def create_context_prompt(user_data):
    """T·∫°o context prompt t·ª´ d·ªØ li·ªáu c·ªßa user"""
    context = """B·∫°n l√† m·ªôt tr·ª£ l√Ω AI th√¥ng minh cho n·ªÅn t·∫£ng h·ªçc t·∫≠p c√° nh√¢n h√≥a. 
Nhi·ªám v·ª• c·ªßa b·∫°n l√†:
1. Tr·∫£ l·ªùi c√¢u h·ªèi v·ªÅ c√°c ch·ªß ƒë·ªÅ h·ªçc t·∫≠p
2. Gi·∫£i th√≠ch c√°c kh√°i ni·ªám ph·ª©c t·∫°p m·ªôt c√°ch ƒë∆°n gi·∫£n
3. ƒê∆∞a ra l·ªùi khuy√™n h·ªçc t·∫≠p d·ª±a tr√™n ti·∫øn ƒë·ªô c·ªßa h·ªçc vi√™n
4. ƒê·ªông vi√™n v√† h·ªó tr·ª£ h·ªçc vi√™n
5. G·ª£i √Ω c√°c t√†i nguy√™n v√† b√†i t·∫≠p ph√π h·ª£p

H√£y tr·∫£ l·ªùi b·∫±ng ti·∫øng Vi·ªát, th√¢n thi·ªán, nhi·ªát t√¨nh v√† chi ti·∫øt.
"""
    
    # Th√™m th√¥ng tin v·ªÅ roadmaps
    if user_data.get('roadmaps'):
        context += "\n\nüìö **C√°c kh√≥a h·ªçc ƒëang h·ªçc:**\n"
        for topic, details in user_data['roadmaps'].items():
            context += f"- {topic}\n"
            for week, week_data in details.items():
                if isinstance(week_data, dict):
                    topic_name = week_data.get('ch·ªß ƒë·ªÅ') or week_data.get('topic', '')
                    if topic_name:
                        context += f"  ‚Ä¢ {week}: {topic_name}\n"
    
    # Th√™m th√¥ng tin v·ªÅ quiz stats
    if user_data.get('quizStats'):
        context += "\n\nüìä **K·∫øt qu·∫£ b√†i ki·ªÉm tra:**\n"
        for topic, weeks in user_data['quizStats'].items():
            context += f"- {topic}:\n"
            for week, subtopics in weeks.items():
                if isinstance(subtopics, dict):
                    for subtopic, stats in subtopics.items():
                        if isinstance(stats, dict):
                            percent = (stats.get('numCorrect', 0) * 100 / stats.get('numQues', 1))
                            context += f"  ‚Ä¢ Tu·∫ßn {week}, Ch·ªß ƒë·ªÅ {subtopic}: {percent:.1f}% ƒë√∫ng\n"
    
    # Th√™m th√¥ng tin v·ªÅ resources ƒë√£ l∆∞u
    if user_data.get('resourceCount'):
        context += f"\n\nüíæ **T√†i nguy√™n ƒë√£ l∆∞u:** {user_data['resourceCount']} t√†i li·ªáu\n"
    
    return context

def chat_with_ai_sync(messages, user_data=None):
    """
    Chat v·ªõi AI s·ª≠ d·ª•ng OpenAI API (ƒë·ªìng b·ªô - blocking)
    
    Args:
        messages: List of message objects [{"role": "user/assistant", "content": "..."}]
        user_data: Dict ch·ª©a roadmaps, quizStats, resources c·ªßa user
    
    Returns:
        String response t·ª´ AI
    """
    try:
        # T·∫°o context prompt
        context_prompt = create_context_prompt(user_data or {})
        
        # Th√™m system message v·ªõi context
        system_message = {
            "role": "system",
            "content": context_prompt
        }
        
        # K·∫øt h·ª£p system message v·ªõi messages
        full_messages = [system_message] + messages
        
        # G·ªçi OpenAI API
        response = client.chat.completions.create(
            model=os.environ.get("OPENAI_MODEL", "gpt-5-nano-2025-08-07"),
            messages=full_messages,
            temperature=0.7
        )
        
        return response.choices[0].message.content
        
    except Exception as e:
        print(f"L·ªói khi g·ªçi OpenAI API: {str(e)}")
        raise e

def process_chat_job(job_id, messages, user_data):
    """X·ª≠ l√Ω chat job trong background thread"""
    try:
        print(f"[Chat Job {job_id}] B·∫Øt ƒë·∫ßu x·ª≠ l√Ω...")
        chat_job_storage[job_id]['status'] = 'processing'
        chat_job_storage[job_id]['updated_at'] = datetime.now().isoformat()
        
        # G·ªçi AI ƒë·ªÉ chat
        result = chat_with_ai_sync(messages, user_data)
        
        # C·∫≠p nh·∫≠t k·∫øt qu·∫£
        chat_job_storage[job_id]['status'] = 'completed'
        chat_job_storage[job_id]['result'] = result
        chat_job_storage[job_id]['updated_at'] = datetime.now().isoformat()
        chat_job_storage[job_id]['completed_at'] = datetime.now().isoformat()
        
        print(f"[Chat Job {job_id}] Ho√†n th√†nh!")
        
    except Exception as e:
        print(f"[Chat Job {job_id}] L·ªói: {str(e)}")
        chat_job_storage[job_id]['status'] = 'failed'
        chat_job_storage[job_id]['error'] = str(e)
        chat_job_storage[job_id]['updated_at'] = datetime.now().isoformat()

def chat_with_ai(messages, user_data=None):
    """
    T·∫°o chat job v√† tr·∫£ v·ªÅ job_id ngay l·∫≠p t·ª©c
    
    Args:
        messages: List of message objects [{"role": "user/assistant", "content": "..."}]
        user_data: Dict ch·ª©a roadmaps, quizStats, resources c·ªßa user
    
    Returns:
        String job_id
    """
    job_id = str(uuid.uuid4())
    
    # Kh·ªüi t·∫°o job
    chat_job_storage[job_id] = {
        'job_id': job_id,
        'status': 'pending',
        'messages': messages,
        'user_data': user_data,
        'created_at': datetime.now().isoformat(),
        'updated_at': datetime.now().isoformat(),
        'result': None,
        'error': None
    }
    
    # Ch·∫°y x·ª≠ l√Ω trong background thread
    thread = threading.Thread(
        target=process_chat_job,
        args=(job_id, messages, user_data)
    )
    thread.daemon = True
    thread.start()
    
    print(f"[Chat Job {job_id}] ƒê√£ t·∫°o v√† b·∫Øt ƒë·∫ßu background processing")
    
    return job_id

def get_chat_job_status(job_id):
    """L·∫•y tr·∫°ng th√°i c·ªßa chat job"""
    if job_id not in chat_job_storage:
        return None
    return chat_job_storage[job_id]
