"""
Module x·ª≠ l√Ω Personalized Recommendations v·ªõi AI
G·ª£i √Ω ch·ªß ƒë·ªÅ ti·∫øp theo, learning path, v√† ƒëi·ªÅu ch·ªânh ƒë·ªô kh√≥ d·ª±a tr√™n performance
T·ªëi ∆∞u v·ªõi parallel processing ƒë·ªÉ gi·∫£m th·ªùi gian response
"""
from openai import OpenAI
import os
from dotenv import load_dotenv
import json
from datetime import datetime
from concurrent.futures import ThreadPoolExecutor, as_completed
import time

load_dotenv()

# Kh·ªüi t·∫°o OpenAI client
client = OpenAI(
    api_key=os.getenv('OPENAI_API_KEY'),
    base_url=os.getenv('OPENAI_BASE_URL', 'https://v98store.com/v1')
)

MODEL = os.getenv('OPENAI_MODEL', 'gpt-5-nano-2025-08-07')

# ThreadPoolExecutor ƒë·ªÉ ch·∫°y parallel AI requests
executor = ThreadPoolExecutor(max_workers=3)


def analyze_performance(learning_data):
    """
    Ph√¢n t√≠ch performance c·ªßa user ƒë·ªÉ ƒë∆∞a ra recommendations
    
    Returns:
        Dict ch·ª©a performance summary, strengths, weaknesses
    """
    quiz_results = learning_data.get('quiz_results', [])
    time_spent = learning_data.get('time_spent', {})
    topics = learning_data.get('current_topics', [])
    
    if not quiz_results:
        return {
            'avg_score': 0,
            'total_quizzes': 0,
            'topics_studied': 0,
            'strong_topics': [],
            'weak_topics': [],
            'total_time_hours': 0,
            'topic_performance': {},
            'recent_trend': 'insufficient_data'
        }
    
    # T√≠nh ƒëi·ªÉm trung b√¨nh
    avg_score = sum(q['score'] for q in quiz_results) / len(quiz_results)
    
    # Ph√¢n t√≠ch theo topic
    topic_performance = {}
    for topic in topics:
        topic_quizzes = [q for q in quiz_results if q['topic'] == topic]
        if topic_quizzes:
            topic_avg = sum(q['score'] for q in topic_quizzes) / len(topic_quizzes)
            topic_performance[topic] = {
                'avg_score': topic_avg,
                'quizzes': len(topic_quizzes),
                'time_spent': time_spent.get(topic, 0)
            }
    
    # X√°c ƒë·ªãnh strong v√† weak topics
    strong_topics = [
        {'topic': topic, 'score': data['avg_score']} 
        for topic, data in topic_performance.items() 
        if data['avg_score'] >= 80
    ]
    
    weak_topics = [
        {'topic': topic, 'score': data['avg_score']} 
        for topic, data in topic_performance.items() 
        if data['avg_score'] < 70
    ]
    
    # S·∫Øp x·∫øp
    strong_topics.sort(key=lambda x: x['score'], reverse=True)
    weak_topics.sort(key=lambda x: x['score'])
    
    # T√≠nh trend t·ª´ quiz g·∫ßn nh·∫•t
    recent_quizzes = quiz_results[-5:]
    recent_trend = 'insufficient_data'
    if len(recent_quizzes) >= 3:
        recent_avg = sum(q['score'] for q in recent_quizzes) / len(recent_quizzes)
        recent_trend = "improving" if recent_avg > avg_score else "stable"
    
    return {
        'avg_score': round(avg_score, 1),
        'total_quizzes': len(quiz_results),
        'topics_studied': len(topics),
        'strong_topics': strong_topics,
        'weak_topics': weak_topics,
        'total_time_hours': round(sum(time_spent.values()) / 3600, 1),
        'topic_performance': topic_performance,
        'recent_trend': recent_trend,
        'recent_scores': [q['score'] for q in recent_quizzes[-3:]]
    }


def recommend_next_topics(learning_data, performance):
    """
    S·ª≠ d·ª•ng AI ƒë·ªÉ g·ª£i √Ω c√°c ch·ªß ƒë·ªÅ ti·∫øp theo d·ª±a tr√™n performance
    T·ªëi ∆∞u context ƒë·ªÉ gi·∫£m token v√† tƒÉng t·ªëc ƒë·ªô
    
    Returns:
        List of recommended topics v·ªõi l√Ω do, ƒë·ªô ∆∞u ti√™n, estimated time
    """
    try:
        # Chu·∫©n b·ªã context T·ªêI ∆ØU - ch·ªâ nh·ªØng th√¥ng tin c·∫ßn thi·∫øt
        # Fix: An to√†n h∆°n khi format topics
        strong_topics_list = performance.get('strong_topics', [])[:3]
        weak_topics_list = performance.get('weak_topics', [])[:3]
        
        strong_topics_str = ", ".join([f"{t.get('topic', 'N/A')} ({t.get('score', 0):.1f}%)" for t in strong_topics_list]) if strong_topics_list else "Ch∆∞a c√≥"
        weak_topics_str = ", ".join([f"{t.get('topic', 'N/A')} ({t.get('score', 0):.1f}%)" for t in weak_topics_list]) if weak_topics_list else "Ch∆∞a c√≥"
        
        context = f"""Ph√¢n t√≠ch h·ªçc t·∫≠p:
- ƒêi·ªÉm TB: {performance.get('avg_score', 0)}%, {performance.get('total_quizzes', 0)} quiz, {performance.get('topics_studied', 0)} topics
- M·∫°nh: {strong_topics_str}
- Y·∫øu: {weak_topics_str}
- Xu h∆∞·ªõng: {performance.get('recent_trend', 'N/A')}"""
        
        response = client.chat.completions.create(
            model=MODEL,
            messages=[
                {
                    "role": "system",
                    "content": """AI advisor g·ª£i √Ω l·ªô tr√¨nh h·ªçc t·∫≠p.

Tr·∫£ v·ªÅ JSON:
{
  "performance_summary": "T√≥m t·∫Øt 2 c√¢u",
  "next_topics": [
    {
      "topic": "T√™n topic",
      "reason": "L√Ω do d·ª±a v√†o performance",
      "priority": "high/medium/low",
      "relevance_score": 8,
      "estimated_time": "2-3 tu·∫ßn",
      "prerequisites": ["Ki·∫øn th·ª©c 1"],
      "benefits": ["L·ª£i √≠ch 1"]
    }
  ]
}

QUY T·∫ÆC:
- Weak topics ‚Üí G·ª£i √Ω c·ªßng c·ªë
- Strong topics ‚Üí G·ª£i √Ω n√¢ng cao
- 3-5 topics, ∆∞u ti√™n ph√π h·ª£p nh·∫•t
- TI·∫æNG VI·ªÜT"""
                },
                {
                    "role": "user",
                    "content": context
                }
            ],
            temperature=0.7,
            response_format={"type": "json_object"}
        )
        
        result = json.loads(response.choices[0].message.content)
        return result
        
    except Exception as e:
        print(f"L·ªói khi g·ª£i √Ω topics: {str(e)}")
        import traceback
        traceback.print_exc()
        return {
            "performance_summary": "ƒêang ph√¢n t√≠ch d·ªØ li·ªáu c·ªßa b·∫°n ƒë·ªÉ ƒë∆∞a ra g·ª£i √Ω ph√π h·ª£p.",
            "next_topics": [
                {
                    "topic": "Ch·ªß ƒë·ªÅ m·ªõi",
                    "reason": "Ti·∫øp t·ª•c kh√°m ph√° c√°c lƒ©nh v·ª±c m·ªõi ƒë·ªÉ m·ªü r·ªông ki·∫øn th·ª©c",
                    "priority": "medium",
                    "relevance_score": 7,
                    "estimated_time": "2-3 tu·∫ßn",
                    "prerequisites": [],
                    "benefits": ["M·ªü r·ªông ki·∫øn th·ª©c", "Ph√°t tri·ªÉn k·ªπ nƒÉng m·ªõi"]
                }
            ]
        }


def generate_learning_path(learning_data, performance):
    """
    T·∫°o l·ªô tr√¨nh h·ªçc t·∫≠p chi ti·∫øt (learning path) d·ª±a tr√™n ph√¢n t√≠ch
    T·ªëi ∆∞u context ƒë·ªÉ gi·∫£m token
    
    Returns:
        Dict ch·ª©a learning path v·ªõi c√°c milestones
    """
    try:
        # Context T·ªêI ∆ØU
        context = f"""T·∫°o l·ªô tr√¨nh cho:
- Level: {performance['avg_score']}%, {performance['topics_studied']} topics
- M·∫°nh: {len(performance['strong_topics'])} topics
- C·∫ßn c·∫£i thi·ªán: {len(performance['weak_topics'])} topics"""
        
        response = client.chat.completions.create(
            model=MODEL,
            messages=[
                {
                    "role": "system",
                    "content": """Learning Path Designer.

Tr·∫£ v·ªÅ JSON:
{
  "title": "Ti√™u ƒë·ªÅ l·ªô tr√¨nh",
  "description": "M√¥ t·∫£ 2 c√¢u",
  "total_duration": "3-4 th√°ng",
  "milestones": [
    {
      "title": "Milestone 1: T√™n giai ƒëo·∫°n",
      "duration": "2-3 tu·∫ßn",
      "description": "M√¥ t·∫£",
      "topics": ["Topic 1", "Topic 2"],
      "goals": ["M·ª•c ti√™u 1"]
    }
  ]
}

QUY T·∫ÆC:
- 4-6 milestones
- B·∫Øt ƒë·∫ßu v·ªõi n·ªÅn t·∫£ng
- K·∫øt th√∫c v·ªõi n√¢ng cao
- TI·∫æNG VI·ªÜT"""
                },
                {
                    "role": "user",
                    "content": context
                }
            ],
            temperature=0.7,
            response_format={"type": "json_object"}
        )
        
        result = json.loads(response.choices[0].message.content)
        return result
        
    except Exception as e:
        print(f"L·ªói khi t·∫°o learning path: {str(e)}")
        return {
            "title": "L·ªô tr√¨nh h·ªçc t·∫≠p c√° nh√¢n h√≥a",
            "description": "L·ªô tr√¨nh ƒë∆∞·ª£c thi·∫øt k·∫ø d·ª±a tr√™n m·ª©c ƒë·ªô v√† m·ª•c ti√™u c·ªßa b·∫°n",
            "total_duration": "3-6 th√°ng",
            "milestones": [
                {
                    "title": "Giai ƒëo·∫°n 1: C·ªßng c·ªë n·ªÅn t·∫£ng",
                    "duration": "1-2 th√°ng",
                    "description": "Ho√†n thi·ªán c√°c ki·∫øn th·ª©c c∆° b·∫£n",
                    "topics": ["C√°c ch·ªß ƒë·ªÅ n·ªÅn t·∫£ng"],
                    "goals": ["N·∫Øm v·ªØng ki·∫øn th·ª©c c∆° b·∫£n"]
                }
            ]
        }


def adjust_difficulty(learning_data, performance):
    """
    ƒê·ªÅ xu·∫•t ƒëi·ªÅu ch·ªânh ƒë·ªô kh√≥ d·ª±a tr√™n performance
    T·ªëi ∆∞u context
    
    Returns:
        Dict ch·ª©a current level, recommended level, reason
    """
    try:
        avg_score = performance['avg_score']
        trend = performance['recent_trend']
        recent_scores = performance.get('recent_scores', [])
        
        # X√°c ƒë·ªãnh level hi·ªán t·∫°i
        if avg_score >= 90:
            current_level = 'advanced'
        elif avg_score >= 75:
            current_level = 'intermediate'
        elif avg_score >= 60:
            current_level = 'beginner'
        else:
            current_level = 'beginner'
        
        # Context T·ªêI ∆ØU
        context = f"""ƒêi·ªÅu ch·ªânh ƒë·ªô kh√≥:
- ƒêi·ªÉm TB: {avg_score}%, Level: {current_level}
- Xu h∆∞·ªõng: {trend}
- ƒêi·ªÉm g·∫ßn nh·∫•t: {recent_scores}"""
        
        response = client.chat.completions.create(
            model=MODEL,
            messages=[
                {
                    "role": "system",
                    "content": """AI Difficulty Specialist.

Tr·∫£ v·ªÅ JSON:
{
  "current_level": "beginner/intermediate/advanced/expert",
  "recommended_difficulty": "beginner/intermediate/advanced/expert",
  "reason": "L√Ω do 2 c√¢u",
  "adjustment_tips": ["Tip 1", "Tip 2"]
}

QUY T·∫ÆC:
- beginner: <70%, intermediate: 70-84%, advanced: 85-94%, expert: ‚â•95%
- ƒêi·ªÉm cao & ·ªïn ƒë·ªãnh ‚Üí tƒÉng ƒë·ªô kh√≥
- ƒêi·ªÉm th·∫•p ‚Üí gi·ªØ nguy√™n/gi·∫£m
- TI·∫æNG VI·ªÜT"""
                },
                {
                    "role": "user",
                    "content": context
                }
            ],
            temperature=0.7,
            response_format={"type": "json_object"}
        )
        
        result = json.loads(response.choices[0].message.content)
        return result
        
    except Exception as e:
        print(f"L·ªói khi ƒëi·ªÅu ch·ªânh difficulty: {str(e)}")
        return {
            "current_level": "intermediate",
            "recommended_difficulty": "intermediate",
            "reason": "Ti·∫øp t·ª•c v·ªõi ƒë·ªô kh√≥ hi·ªán t·∫°i ƒë·ªÉ c·ªßng c·ªë ki·∫øn th·ª©c",
            "adjustment_tips": ["L√†m th√™m quiz ƒë·ªÉ ƒë√°nh gi√° ch√≠nh x√°c h∆°n"]
        }


def get_personalized_recommendations(learning_data):
    """
    Main function: T·ªïng h·ª£p t·∫•t c·∫£ recommendations v·ªõi PARALLEL PROCESSING
    Ch·∫°y 3 AI requests ƒë·ªìng th·ªùi thay v√¨ tu·∫ßn t·ª± ƒë·ªÉ gi·∫£m th·ªùi gian response
    
    Returns:
        Dict ch·ª©a:
        - next_topics: C√°c ch·ªß ƒë·ªÅ n√™n h·ªçc ti·∫øp
        - learning_path: L·ªô tr√¨nh h·ªçc t·∫≠p chi ti·∫øt
        - difficulty_adjustment: ƒêi·ªÅu ch·ªânh ƒë·ªô kh√≥
        - general_tips: C√°c tips chung
    """
    start_time = time.time()
    print("üöÄ B·∫Øt ƒë·∫ßu ph√¢n t√≠ch recommendations (parallel mode)...")
    
    # Ph√¢n t√≠ch performance (local, r·∫•t nhanh)
    performance = analyze_performance(learning_data)
    print(f"‚úÖ Performance analyzed: {performance['avg_score']}% avg, {performance['total_quizzes']} quizzes")
    
    # Ch·∫°y 3 AI requests PARALLEL thay v√¨ tu·∫ßn t·ª±
    # ƒêi·ªÅu n√†y gi·∫£m th·ªùi gian t·ª´ ~6-9s xu·ªëng c√≤n ~2-3s
    futures = {}
    
    with ThreadPoolExecutor(max_workers=3) as executor:
        print("‚ö° Submitting 3 parallel AI requests...")
        
        # Submit t·∫•t c·∫£ requests c√πng l√∫c
        futures['topics'] = executor.submit(recommend_next_topics, learning_data, performance)
        futures['path'] = executor.submit(generate_learning_path, learning_data, performance)
        futures['difficulty'] = executor.submit(adjust_difficulty, learning_data, performance)
        
        # ƒê·ª£i t·∫•t c·∫£ ho√†n th√†nh v√† l·∫•y k·∫øt qu·∫£
        results = {}
        for key, future in futures.items():
            try:
                results[key] = future.result(timeout=15)  # Timeout 15s cho m·ªói request
                print(f"‚úÖ {key} completed")
            except Exception as e:
                print(f"‚ùå Error in {key}: {str(e)}")
                import traceback
                traceback.print_exc()  # In full traceback ƒë·ªÉ debug
                
                # Fallback n·∫øu c√≥ l·ªói
                if key == 'topics':
                    results[key] = {
                        "performance_summary": "ƒêang ph√¢n t√≠ch d·ªØ li·ªáu c·ªßa b·∫°n",
                        "next_topics": []
                    }
                elif key == 'path':
                    results[key] = {
                        "title": "L·ªô tr√¨nh h·ªçc t·∫≠p",
                        "description": "ƒêang t·∫°o l·ªô tr√¨nh ph√π h·ª£p",
                        "total_duration": "3-6 th√°ng",
                        "milestones": []
                    }
                else:  # difficulty
                    results[key] = {
                        "current_level": "intermediate",
                        "recommended_difficulty": "intermediate",
                        "reason": "ƒêang ph√¢n t√≠ch",
                        "adjustment_tips": []
                    }
    
    # General tips d·ª±a tr√™n performance
    general_tips = []
    
    if performance['avg_score'] < 70:
        general_tips.append("H√£y d√†nh nhi·ªÅu th·ªùi gian h∆°n ƒë·ªÉ √¥n l·∫°i c√°c concepts c∆° b·∫£n tr∆∞·ªõc khi h·ªçc topics m·ªõi")
        general_tips.append("Th·ª≠ l√†m l·∫°i c√°c quiz c≈© ƒë·ªÉ c·ªßng c·ªë ki·∫øn th·ª©c")
    
    if performance['topics_studied'] < 3:
        general_tips.append("H√£y kh√°m ph√° th√™m nhi·ªÅu topics kh√°c nhau ƒë·ªÉ t√¨m ra lƒ©nh v·ª±c b·∫°n y√™u th√≠ch")
    
    if performance['total_time_hours'] < 2:
        general_tips.append("D√†nh √≠t nh·∫•t 30 ph√∫t m·ªói ng√†y ƒë·ªÉ h·ªçc t·∫≠p s·∫Ω gi√∫p b·∫°n ti·∫øn b·ªô nhanh h∆°n")
    
    if performance['weak_topics']:
        general_tips.append("T·∫≠p trung v√†o c√°c topics b·∫°n c√≤n y·∫øu s·∫Ω gi√∫p tƒÉng ƒëi·ªÉm s·ªë t·ªïng th·ªÉ")
    
    if not general_tips:
        general_tips.append("B·∫°n ƒëang h·ªçc t·∫≠p r·∫•t t·ªët! H√£y ti·∫øp t·ª•c duy tr√¨ nh·ªãp ƒë·ªô n√†y")
        general_tips.append("Th·ª≠ th√°ch b·∫£n th√¢n v·ªõi c√°c topics n√¢ng cao h∆°n")
    
    elapsed_time = time.time() - start_time
    print(f"üéâ Recommendations completed in {elapsed_time:.2f}s (parallel mode)")
    
    return {
        'recommendations': {
            'performance_summary': results['topics'].get('performance_summary', ''),
            'general_tips': general_tips
        },
        'next_topics': results['topics'].get('next_topics', []),
        'learning_path': results['path'],
        'difficulty_adjustment': results['difficulty'],
        'performance': performance,
        'processing_time': round(elapsed_time, 2)
    }
